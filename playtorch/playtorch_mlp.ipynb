{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfbacc98",
   "metadata": {},
   "source": [
    "# PlayTorch â€” Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e5f0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafif/Documents/PhD Research/phd2030/.venv/lib/python3.12/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 50000 Test size: 10000\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "# ---------- 1) Device ----------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# ---------- 2) Data ----------\n",
    "# CIFAR-10 images are 32x32 RGB. We convert to tensor and normalize.\n",
    "# Normalization uses per-channel mean/std commonly used for CIFAR-10.\n",
    "transform_train = T.Compose([\n",
    "    T.RandomHorizontalFlip(),          # light augmentation\n",
    "    T.RandomCrop(32, padding=4),       # light augmentation\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.CIFAR10(\n",
    "    root=\"./datasets\", train=True, download=True, transform=transform_train\n",
    ")\n",
    "test_ds = torchvision.datasets.CIFAR10(\n",
    "    root=\"./datasets\", train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "classes = train_ds.classes\n",
    "print(\"Train size:\", len(train_ds), \"Test size:\", len(test_ds))\n",
    "print(\"Classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285fce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ---------- 3) Model (MLP) ----------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3*32*32, num_classes=10): \n",
    "        super().__init__()          # Initialize the parent class\n",
    "        self.net = nn.Sequential(   # Define the network architecture\n",
    "            nn.Linear(in_dim, 512), # Input layer\n",
    "            nn.ReLU(),              # Activation function\n",
    "            nn.Linear(512, 256),    # Hidden layer\n",
    "            nn.ReLU(),              # Activation function\n",
    "            nn.Linear(256, 128),    # Hidden layer\n",
    "            nn.ReLU(),              # Activation function\n",
    "            nn.Linear(128, num_classes) # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # Define the forward pass\n",
    "        x = x.flatten(1)  # Flatten the input tensor\n",
    "        return self.net(x)\n",
    "    \n",
    "model = MLP().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d21b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4) Loss + Optimizer ----------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ---------- 5) Training Loop ----------\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47622c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 1.8087, Train Acc: 0.3470 | Test Loss: 1.6492, Test Acc: 0.4103\n",
      "Epoch 2/10: Train Loss: 1.6419, Train Acc: 0.4094 | Test Loss: 1.6077, Test Acc: 0.4221\n",
      "Epoch 3/10: Train Loss: 1.5649, Train Acc: 0.4401 | Test Loss: 1.5847, Test Acc: 0.4335\n",
      "Epoch 4/10: Train Loss: 1.5187, Train Acc: 0.4530 | Test Loss: 1.6076, Test Acc: 0.4270\n",
      "Epoch 5/10: Train Loss: 1.4789, Train Acc: 0.4681 | Test Loss: 1.5108, Test Acc: 0.4636\n",
      "Epoch 6/10: Train Loss: 1.4529, Train Acc: 0.4767 | Test Loss: 1.5482, Test Acc: 0.4420\n",
      "Epoch 7/10: Train Loss: 1.4317, Train Acc: 0.4833 | Test Loss: 1.5217, Test Acc: 0.4645\n",
      "Epoch 8/10: Train Loss: 1.4045, Train Acc: 0.4960 | Test Loss: 1.5072, Test Acc: 0.4742\n",
      "Epoch 9/10: Train Loss: 1.3928, Train Acc: 0.4977 | Test Loss: 1.4567, Test Acc: 0.4814\n",
      "Epoch 10/10: Train Loss: 1.3806, Train Acc: 0.5013 | Test Loss: 1.4982, Test Acc: 0.4741\n"
     ]
    }
   ],
   "source": [
    "# ---------- 6) Run Training ----------\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd2030 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
